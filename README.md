# ERRA: An Embodied Representation and Reasoning Architecture for Long-horizon Language-conditioned Manipulation Tasks

## 1. Overview



https://user-images.githubusercontent.com/32490390/229056938-3ed035f8-6682-4c21-8b7c-6a513dbe81fb.mp4



## 2. Prerequisites
### 2.1 Hardware
- [**Universal Robot UR10**](https://www.universal-robots.com/products/ur10-robot/)
- [**RealSense Camera L515**](https://www.intelrealsense.com/lidar-camera-l515/)
- [**Tactile sensor**](https://item.taobao.com/item.htm?spm=a230r.1.14.34.4eec36a9Odc33z&id=621053142375&ns=1&abbucket=3#detail)
### 2.2 Software
The code is built with Python 3.6. Dependencies are listed in requirements.yaml and can be installed via [Anaconda](https://www.anaconda.com/) by running:

    conda env create -n new_env -f environment.yml
    
### 2.3 Language Model 
[Model download](https://drive.google.com/drive/folders/1rpjwhV7bY5b26ZMyW8jvDhZP_gIh2dr_?usp=share_link)

